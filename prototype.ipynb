{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './dataset/all/'\n",
    "\n",
    "\n",
    "EMOTION_DICT_RAVDEES = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\",\n",
    "}\n",
    "\n",
    "def decompose_label(file_path: str):\n",
    "    return label_to_int[file_path.split(\"-\")[2]]\n",
    "\n",
    "file_path_list = os.listdir(DATA_DIR)\n",
    "label_to_int = dict({(key, i) for i, key in enumerate(EMOTION_DICT_RAVDEES.keys())})\n",
    "labels = [decompose_label(file_path) for file_path in file_path_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potential class weights ? \n",
    "# total = np.sum(train_df['label'].value_counts())\n",
    "# class_weights = [1-(x/total) for x in train_df['label'].value_counts()]\n",
    "# class_weights = np.array(class_weights)/6\n",
    "# class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SR = 22050 for ravdees\n",
    "import tensorflow_io as tfio\n",
    "file_contents = tf.io.read_file(os.path.join(DATA_DIR, file_path_list[0]))\n",
    "print(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav(file_path, sr=22050):\n",
    "    pre_emp = 0.97\n",
    "    file_contents = tf.io.read_file(file_path)\n",
    "\n",
    "    # Default SR is 22050, putting desired_samples to 66150 to get 3 second sample\n",
    "    wav, sr = tf.audio.decode_wav(\n",
    "        file_contents, desired_channels=1, desired_samples=66150\n",
    "    )\n",
    "\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "\n",
    "    # Apply preamp if needed\n",
    "    wav = tf.experimental.numpy.append(wav[0], wav[1:] - pre_emp * wav[:-1])\n",
    "\n",
    "    return wav\n",
    "\n",
    "\n",
    "def get_mfcc(wav, sr=22050):\n",
    "    stft_out = tf.signal.stft(\n",
    "        wav, 400, 160, window_fn=tf.signal.hamming_window, pad_end=False\n",
    "    )\n",
    "    num_spectrogram_bins = tf.shape(stft_out)[-1]\n",
    "    stft_abs = tf.abs(stft_out)\n",
    "    lower_edge_hz, upper_edge_hz = 20.0, 8000.0\n",
    "    num_mel_bins = 64\n",
    "    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "        num_mel_bins, num_spectrogram_bins, 16000, lower_edge_hz, upper_edge_hz\n",
    "    )\n",
    "    mel_spectrograms = tf.tensordot(stft_abs, linear_to_mel_weight_matrix, 1)\n",
    "    mel_spectrograms.set_shape(stft_abs.shape[:-1].concatenate(linear_to_mel_weight_matrix.shape[-1:]))\n",
    "\n",
    "    log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n",
    "    log_mel_d1 = log_mel_spectrograms - tf.roll(log_mel_spectrograms, -1, axis = 0)\n",
    "    log_mel_d2 = log_mel_d1 - tf.roll(log_mel_d1, -1, axis = 0)\n",
    "\n",
    "    log_mel_three_channel = tf.stack([log_mel_spectrograms, log_mel_d1, log_mel_d2], axis = -1)\n",
    "    \n",
    "    framed_log_mels = tf.signal.frame(log_mel_three_channel, frame_length=64, frame_step=32, pad_end=False, axis = 0)\n",
    "\n",
    "    return framed_log_mels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_path_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1319/3715906342.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_fps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_fps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'file_path_list' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_fps, val_fps, train_labels, val_labels = train_test_split(file_path_list, labels, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "        \n",
    "    filepaths = train_df['filename']\n",
    "    labels = train_df['label']\n",
    "\n",
    "    filepaths, labels = shuffle(filepaths, labels)\n",
    "    train_fps, val_fps, train_labels, val_labels = train_test_split(filepaths, labels, test_size = 0.1)\n",
    "\n",
    "    train_files_ds = tf.data.Dataset.from_tensor_slices(train_fps)\n",
    "    train_wav_ds = train_files_ds.map(load_wav, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    train_mfcc_ds = train_wav_ds.map(get_mfcc, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    train_labels_ds = tf.data.Dataset.from_tensor_slices(train_labels)\n",
    "\n",
    "    train_ds = tf.data.Dataset.zip((train_mfcc_ds, train_labels_ds))\n",
    "\n",
    "    val_files_ds = tf.data.Dataset.from_tensor_slices(val_fps)\n",
    "    val_wav_ds = val_files_ds.map(load_wav_no_augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    val_mfcc_ds = val_wav_ds.map(get_mfcc, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    val_labels_ds = tf.data.Dataset.from_tensor_slices(val_labels)\n",
    "\n",
    "    val_ds = tf.data.Dataset.zip((val_mfcc_ds, val_labels_ds))\n",
    "\n",
    "    train_ds = train_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return train_ds, val_ds"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
